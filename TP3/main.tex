\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{subcaption}
\usepackage{mwe}
\usepackage{listings}
\usepackage[section]{placeins}
\usepackage[export]{adjustbox}

\pagestyle{plain}
\pagenumbering{arabic}


\title{Informe del Trabajo Práctico 3: Machine Learning}

\author{Agüero, Emanuel\\
\and
Bustillo, Carlos\\
\and
Lezcano, Agustín\\
}

\date{04 de septiembre de 2020}

\begin{document}

\maketitle

\section{Introducción}

El objetivo del trabajo práctico es implementar una  red neuronal feedforward fully connected de 1 capa oculta
para poder clasificar tres grupos distintos generados de manera ficticia, mediante la implementación de un MLP. 

El número de entradas son dos (según los ejes de las coordenadas cartesianas) y al ser tres grupos, las salidas son  3.

\section{Accuracy y Loss}
Se busca el máximo de cada fila en la salida real y  se obtiene un vector de 300x1 (se encuentra el índice donde está el valor máximo de la lista). Posteriormente se compara fila por fila el valor del vector (que es el máximo de cada fila de) con la salida target donde coincida. Si coincide le asigna el valor 1, sino 0. Finalmente se realiza el promedio de las clases acertadas sobre el total de ejemplos tomados para obtener la eficiencia.

El valor de la función de Loss se usa para variar los pesos, cuyos valores cambian según el ritmo de aprendizaje y la función de Loss propiamente dicha. La misma se calcula como el promedio de los logaritmos de los valores P, de la siguiente forma:
\begin{equation}
    L = \frac{1}{m}*\sum(-log(\frac{e^(y^m)_{c}}{\sum_{j}(e^(y)_{j})} 
\end{equation}


\section{Lerning rate, loss y parada temprana}
Se utilizó una pequeña fracción de datos para la validación y para el test. Para la validación se evaluó el desempeño cada  \esemtextbf{n} \textit{epochs}, comparando el valor de Loss entre el \textit{dataset} de validación y el de training. 

El \textit{learning rate} o tasa de aprendizaje es un parámetro de ajuste en un algoritmo de optimización que determina el tamaño del paso en cada iteración mientras se mueve hacia un mínimo de una función de pérdida. En otras palabras, representa la magnitud con el que se mueve en el gradiente mientras que el loss define la dirección.

Se aplicó K fold para tener los parámetros ya optimizados al momento de evaluar el error entre el loss obtenido del Train y el loss obtenido en Validation. Y en caso de que el error absoluto supere el valor de tolerancia deja de estar evaluando. 

Cabe aclarar que cuando se evaluó el K fold, en una primera etapa se varió el learning rate manteniendo fijos los epochs. Luego definido el learning rate se deja fijo y se varían los epochs.

Aclaramos que si se empieza a calcular el error absoluto a partir de un epochs = 0, el error que se comete supera el valor de la tolerancia, por eso solo marca un punto. Por esa razón propusimos que empiece a evaluar el error absoluto entre ambas curvas de lossValidation y lossTrain a partir del 10\% de lo epochs evaluados, para poder dejar que las curvas se estabilicen . 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{TP3_ej3_1.png}
    \caption{Comparar loss del Train vrs Loss de Validation para un valor de tolerancia = 0.3}
    \label{fig:TP3_ej3_1}
\end{figure}

\section{Test: comparación para distintas funciones de datasets}
La idea del test es probar el funcionamiento del algoritmo con los valores que no aprendió antes. Se realizó con el valor de los pesos ya dados mediante el training, o sea que para realizar el test se modifican los mismos. Para el test se creo otro dataset distinto y realizó el \textit{feed forward} una vez para los ejemplos dados, esto quiere decir que se evaluó la función en un \textit{epoch}. Para la evaluación del test se usan métricas de \textit{accuracy}, en este caso se usó el ratio (cantidad de aciertos / cantidad de tests) (esto representa el porcentaje de aciertos). 

Para distintas evaluaciones (test) de los algoritmos usando la función ReLU los resultados de \textit{accuracy} fueron  del orden superior a 90 \%. En cambio, usando una función sigmoidal los resultados de \textit{accuracy} son superiores a 75\%, lo cual indica que según la función sigmoidal planteada y comparando con la función ReLU, la segunda es más eficiente que la primera. Este problema se puede deber al \textit{gradient vanishing}, que significa que debido al gradiente de la función pequeño hacen falta muchas iteraciones para poder lograr valores aceptables de eficiencia durante el entrenamiento.

Para poder visualizar la comparación entre los resultados obtenidos usando una u otra función se realizó un cuadro comparativo (ver tabla \ref{tabla:Cuadro comparativo}). Se debe notar que los valores pueden diferir al ejecutar nuevamente el programa ya que los valores generados cada vez que se ejecuta el programa son aleatorios.

\begin{table}[h]
\scalebox{0.84}{
\begin{tabular}{llll}
\hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Eficiencia \\ en training(reLU)\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Eficiencia\\ en test(reLU)\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Eficiencia \\ en training(sigmoide)\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}Eficiencia \\ en test(sigmoide)\end{tabular}} \\ \hline
0.9933333333333333                                                                            & 0.9333333333333333                                                                      & 0.7533333333333333                                                                               & 0.7333333333333333                                                                           \\
1.0                                                                                           & 1.0                                                                                     & 0.7533333333333333                                                                               & 0.75                                                                                         \\
1.0                                                                                           & 0.9666666666666667                                                                      & 0.8366666666666667                                                                               & 0.7333333333333333                                                                           \\
0.9966666666666667                                                                            & 0.85                                                                                    & 0.77                                                                                             & 0.7333333333333333                                                                           \\
0.99                                                                                          & 0.9                                                                                     & 0.77                                                                                             & 0.7666666666666667                                                                           \\
1.0                                                                                           & 0.9666666666666667                                                                      & 0.77                                                                                             & 0.85                                                                              
\end{tabular}}
\caption{Comparación de los resultados obtenidos para distintas funciones}
\label{tabla:Cuadro comparativo}
\end{table}

\section{Nuevo generador de datasets}
Proponemos la alternativa de funciones gaussianas, para tener un mayor solapamiento entre las clases. Si se desea tener un mayor solapamiento solo se debería modificar la desvición estándar.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{TP3_ej3_2.png}
    \caption{Nuevo conjunto obtenido en el plano}
    \label{fig:TP3_ej3_2}
\end{figure}

Para el Set de datos original se obtuvieron los siguientes resultados:\\
Eficiencia en training 0.9933333333333333\\
Eficiencia en test:  0.9333333333333333

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{TP3_ej3_3.png}
    \caption{Para set de datos original}
    \label{fig:TP3_ej3_3}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{TP3_ej3_4.png}
    \caption{Para el nuevo set de datos}
    \label{fig:TP3_ej3_4}
\end{figure}

Para el nuevo set de datos se obtuvieron los siguientes resultados:\\
Eficiencia en training 0.9466666666666667\\
Eficiencia en test:  0.8

\end{document}